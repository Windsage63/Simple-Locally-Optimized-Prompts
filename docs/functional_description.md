# Functional Description: Simple Locally Optimized Prompts (SLOP)

## Overview

SLOP is a web-based application designed to help users create, optimize, and refine prompts for Large Language Models (LLMs). It interacts with a local or remote LLM API (OpenAI-compatible) to act as an expert prompt engineer.

## User Interface Breakdown

### 1. Header

- **Logo/Title**: Displays the application name.
- **Mode Toggle**: Switch between **Prompts** and **Skills** mode to optimize either prompt ideas or skill specifications.
- **History Button** (`clock-rotate-left` icon): Opens the **History Modal** to view and manage past sessions.
- **Settings Button** (`gear` icon): Opens the **Settings Modal** to configure API connections and models.

### 2. Input Panel (Left/Top)

- **Input Area**: A large text area for users to enter their raw prompt ideas.
- **New Chat / Prompt Button**: Creates a completely new session, clearing the current input, chat history, and results. Use this to start fresh with a new optimization task.
- **Action Bar**:
  - **Include Chat Checkbox**: Toggle whether to include chat history during refinement. When checked, refinement uses the full chat context. When unchecked, refinement compares only the input text against the current result. Note: After each refinement, the chat history resets to provide fresh context for the new optimized prompt version.
  - **Refine Button**: Initiates a refinement process based on the current optimized result. Uses chat history if "Include Chat" is checked, otherwise uses a no-chat refinement approach. During streaming, transforms into a **Stop** button to cancel the operation.
  - **Optimize Button**: Sends the raw prompt from the Input Area to the LLM to generate an initial optimized prompt. This clears the current chat history for a fresh start. During streaming, transforms into a **Stop** button to cancel the operation.
- **Resize Handle**: A draggable bar to adjust the vertical split between the Input Area and the Chat Interface.
- **Chat Interface**:
  - **Chat History**: Displays the conversation between the user and the AI assistant.
  - **Chat Input**: Text area for sending messages to the AI.
  - **Send Button**: Sends the user's message.

### 3. Output Panel (Right/Bottom)

- **Optimized Result**: Displays the generated prompt in an editable text area. Results stream in real-time as they are generated by the LLM. The output is editable, allowing you to make manual adjustments.
- **History Navigation**:
  - **Previous/Next Buttons** (`chevron-left`, `chevron-right`): Navigate through the history of optimized prompts generated in the current session. Click to step through previous versions and compare results.
  - **Counter**: Shows the current position in the result history (e.g., "1 / 3").
  - **History Truncation**: When you refine a prompt, any history entries prior to your current position are discarded. This ensures each refinement builds on the most recent result.
- **Save to Library Button** (`bookmark` icon): Saves the current optimized prompt to the local Prompt Library (IndexedDB). If a prompt with the same name exists, you can choose to overwrite or create a new version.
- **Library Button** (`book` icon): Opens the **Library Modal** to browse, filter, and manage saved prompts.
- **Save Prompt Button** (`download` icon): Downloads the current optimized prompt as a Markdown file (`.md`). The filename is derived from the prompt's name in the YAML frontmatter.
- **Skill Export Behavior**: When Skills mode is enabled and the output matches skill format, the Save button downloads a ZIP containing `SKILL.md` and optional `references/` files in the expected skill folder layout.
- **Copy Button** (`copy` icon): Copies the content of the Optimized Result to the clipboard.

### 5. Skills Mode

When Skills mode is active, Optimize/Refine use skill-specific system prompts that embed Claude skill best practices. Outputs are expected to be valid skill files (single `SKILL.md` or multi-file format with markers) and can be exported as ZIP bundles for easy use in `.github/skills/`.

### 4. Modals

- **Settings Modal**:
  - **Optimize / Refine API Section** (boxed):
    - **API Endpoint**: URL for the LLM API used for optimization and refinement (default: `http://localhost:1234/v1`).
    - **API Key**: Optional key for authentication. "Save Key" checkbox inline controls persistence.
    - **Model Name**: The model identifier to use for optimize/refine operations.
    - **Fetch Models Button**: Retrieves available models from the API.
  - **Chat Assistant API Section** (boxed):
    - **API Endpoint**: URL for the LLM API used for chat conversations (can be different from optimize/refine).
    - **API Key**: Optional key with inline "Save Key" checkbox.
    - **Model Name**: The model identifier for chat operations.
    - **Fetch Models Button**: Retrieves available models from the chat API endpoint.
    - *Note: If left empty, falls back to Optimize/Refine API settings.*
  - **Word Wrap Checkbox**: Toggle word wrapping in the output display.
  - **Customize System Prompts**: Individual buttons to edit each of the four system prompts (Optimize, Refine, Refine No Chat, Chat Assistant).
  - **Save Button**: Applies the settings.
- **History Modal**:
  - Lists saved sessions with their names (derived from the prompt) and timestamps.
  - Allows switching between sessions or deleting them.
- **Library Modal**:
  - Displays all saved prompts from the Prompt Library (stored in IndexedDB).
  - **Search Filter**: Filter prompts by name.
  - **Import Button**: Import a Markdown prompt file into the library.
  - **Delete Button**: Remove the selected prompt from the library.
  - **Download Button**: Export the selected prompt as a Markdown file.
  - **Open Button**: Load the selected prompt into the Optimized Result area for editing or refinement.
- **Prompt Settings Modal**:
  - Allows customization of the four core system prompts:
    - **Optimize Prompt**: The instructions for generating the initial optimized prompt.
    - **Chat Prompt**: The persona for the refinement chat assistant. Supports variables: `{{originalPrompt}}`, `{{optimizedResult}}`.
    - **Refine Prompt**: The instructions for applying refinements with chat context. Supports variables: `{{originalPrompt}}`, `{{currentResult}}`, `{{chatHistory}}`.
    - **Refine (No Chat) Prompt**: The instructions for applying refinements without chat context. Supports variables: `{{originalPrompt}}`, `{{currentResult}}`.
  - **Save Button**: Saves the custom prompt to local storage.
  - **Reset Button**: Reverts the prompt to the hardcoded default.

## Data Persistence

- **Local Storage**: The application saves the current session state (input, chat, results), API settings, and custom system prompts in the browser's Local Storage. All keys are namespaced with a `slop_` prefix (e.g., `slop_api_url`, `slop_sessions`) to avoid collisions with other applications.
- **Mode Preference**: The current optimization mode is stored in Local Storage as `slop_optimization_mode`.
- **IndexedDB**: The Prompt Library uses IndexedDB (`slop_prompt_library` database) to persistently store saved prompts with metadata including name, description, and content.
- **Privacy**: No data is sent to a server other than the configured LLM API.
